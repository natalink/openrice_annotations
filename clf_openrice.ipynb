{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total running time:  85.81694300000001\n",
      "Most similar to good:  [('幾', 0.6673245429992676), ('好好', 0.6174938678741455), ('非常', 0.5948214530944824), ('幾好', 0.5799671411514282), ('呀', 0.5637409687042236), ('好味', 0.5410280227661133), ('超級', 0.538070023059845), ('勁', 0.5350697040557861), ('仲好', 0.5212637186050415), ('雞超', 0.521113395690918)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qt402/.local/lib/python3.5/site-packages/ipykernel_launcher.py:58: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n"
     ]
    }
   ],
   "source": [
    "from gensim import utils\n",
    "import jieba\n",
    "import numpy as np\n",
    "from gensim.models.doc2vec import *\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas\n",
    "import json\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn import neighbors, LogisticRegression\n",
    "num_class = 18\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import time\n",
    "\n",
    "######filtering out non-Chinese comments#########\n",
    "#get_ipython().magic(u'cat comments/uid0.txt | grep -v \"Not comment in Chinese\" > comments/uid0_canto.json') # exclude non-Chinese comments comments\n",
    "#get_ipython().magic(u'cat comments/all_comments | grep -v \"Not comment in Chinese\" > comments/all_canto.json') # exclude non-Chinese comments comments\n",
    "#################################################\n",
    "\n",
    "\n",
    "df_canto = pd.read_json('comments/uid0_canto.json', lines=True)\n",
    "\n",
    "###########remove reviews without comments\n",
    "df_canto['comment'].replace('', np.nan, inplace=True)\n",
    "df_canto.dropna(subset=['comment'],inplace=True)\n",
    "\n",
    "####training data: X = comment; Y = emoji (1-5 scale)\n",
    "train_x = df_canto[['comment']]\n",
    "train_y = df_canto[['worthy']]\n",
    "\n",
    "start = time.clock()\n",
    "\n",
    "\n",
    "########Tokenizing Cantonese text with jieba########\n",
    "dictionary = list() # segmented text\n",
    "for index, sentence in train_x.iterrows():\n",
    "    comment = sentence['comment']\n",
    "    seg = \" \".join(list(jieba.cut(comment)))\n",
    "    dictionary.append([seg])\n",
    "\n",
    "    \n",
    "####put segmented text into a file#####   \n",
    "with open(\"segmented_comments.txt\", \"w\") as f:\n",
    "    for pair in dictionary:        \n",
    "        f.write(\" \".join(pair))\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "documents = TaggedLineDocument(\"segmented_comments.txt\")\n",
    "model = Doc2Vec(documents, vector_size=100, window=8, min_count=1, workers=4)\n",
    "\n",
    "\n",
    "model.save(\"comments_doc2vec.vec\")         \n",
    "end = time.clock()\n",
    "print (\"Total running time: \", end-start)\n",
    "print(\"Most similar to good: \", model.most_similar('好')) # just to test the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first review in original format:  comment    雖然貴. 但真心好食嘅爆汁牛肉餅. 九龍城除咗泰國菜出名外. 仲有呢間. 清真牛肉館. 佢地...\n",
      "Name: 0, dtype: object\n",
      "Emoji rank of the first review:  worthy    3\n",
      "Name: 0, dtype: int64\n",
      "first review in segmented format:  ['雖然 貴 .   但 真心 好 食 嘅 爆 汁 牛肉 餅 .   九龍城 除 咗 泰國菜 出名 外 .   仲有 呢 間 .   清真 牛肉 館 .   佢 地 最 出名 嘅 就 係 呢 個 牛肉 餅 .   細細 一件 已經要 .   價錢 確實 有 啲 貴 .   但 味道 真 係 唔 錯 .   外皮 煎 得 好 香脆 .   一咬落 去 .   啲 湯汁 噴晒出 嚟 .   如果 無經驗者 .   真 係 超 容易 整污 糟件 衫 .   其實 我 差少少 都 中招 .   好彩 身手 敏捷 .   避開 咗 .   另外 佢 肉 味 香 濃 .   口感 飽滿 .   以 牛肉 餅呢 講 .   佢 都 算 一 哥 .   如果 佢 係 旺 區 開 分店 就 好 啦 .   咁 就 唔 洗 吓 吓碌入 九龍城 先食 到']\n",
      "first review in doc2vec format:  [ 7.03203678e-02  1.03436872e-01  9.81666446e-02 -2.11124554e-01\n",
      "  2.25318759e-03  1.40257671e-01 -8.35996941e-02  4.61226143e-02\n",
      " -3.49120386e-02 -1.32962922e-02 -5.50856031e-02  8.08985680e-02\n",
      " -1.51788685e-02  2.92610209e-02  5.13075758e-03 -2.64100172e-02\n",
      " -1.28817603e-01  6.25235289e-02  5.54200150e-02 -6.27737790e-02\n",
      "  1.02614313e-01 -8.15101340e-03  2.64504217e-02 -2.73429696e-02\n",
      "  1.52450219e-01 -8.46602321e-02 -1.20728418e-01 -4.04941104e-02\n",
      " -2.30856482e-02  1.15710925e-02  1.47214923e-02  7.04712123e-02\n",
      " -4.61354218e-02 -3.83231975e-02  6.57408237e-02  8.78040213e-03\n",
      "  2.95152664e-02 -1.08188400e-02 -1.76105410e-01  9.03003961e-02\n",
      "  1.10653259e-01 -1.97684346e-03 -5.62968403e-02  7.69948959e-03\n",
      " -5.25918268e-02  1.37983682e-02 -6.93350956e-02 -1.09459817e-01\n",
      "  1.99113283e-02  3.98381473e-03 -5.23219183e-02  9.23904008e-05\n",
      "  1.36664763e-01 -8.78827125e-02  4.32651900e-02  5.82353473e-02\n",
      " -8.47074762e-02 -1.48602352e-01 -1.15480788e-01  5.31663373e-02\n",
      " -1.25843778e-01 -4.35238983e-03  9.06595290e-02  4.72960179e-04\n",
      "  1.71654485e-02 -1.69566255e-02  7.30497204e-03 -7.30732903e-02\n",
      " -8.46268162e-02 -3.58677767e-02  9.32908282e-02  1.25916973e-01\n",
      " -7.43414462e-02  5.88643178e-02  1.87879652e-01  5.30248396e-02\n",
      "  6.71420395e-02 -3.52660343e-02  2.20586844e-02 -1.15978330e-01\n",
      " -1.01684898e-01 -1.44864824e-02  1.00707397e-01 -4.32045758e-02\n",
      "  2.67406111e-03  5.01355603e-02  8.82014632e-02  4.36694212e-02\n",
      " -5.60662802e-03 -2.67266724e-02  9.60002542e-02  4.13028151e-02\n",
      "  1.95741523e-02  1.06908120e-02  1.16921552e-02  6.58634752e-02\n",
      " -1.05757296e-01 -8.71885568e-03  3.26059461e-02 -1.39882252e-01]\n"
     ]
    }
   ],
   "source": [
    "#########Testing the model###########\n",
    "\n",
    "print (\"first review in original format: \", train_x.iloc[0] )\n",
    "print (\"Emoji rank of the first review: \", train_y.iloc[0] )\n",
    "print (\"first review in segmented format: \", dictionary[0] )\n",
    "print (\"first review in doc2vec format: \", model.docvecs[0] )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_line = len(model.docvecs)\n",
    "\n",
    "#######Put the doc2vec representation for each comment into an array\n",
    "x_vecs = np.zeros((num_line, 100))\n",
    "for i in range(0,num_line):\n",
    "    x_vecs[i] = model.docvecs[i]\n",
    "\n",
    "#######Put y_labels (without column names) into an array    \n",
    "y_label = []\n",
    "for index, label in train_y.iterrows():\n",
    "    label_only = label['worthy']\n",
    "    y_label.append(label_only)\n",
    "\n",
    "######Slice the first 1000 lines to make a \n",
    "######Normally, we should have done some cross-validation\n",
    "train_num = 1000\n",
    "X_test = x_vecs[:train_num]\n",
    "Y_test = y_label[:train_num]\n",
    "X_train = x_vecs[train_num+1:]\n",
    "Y_train = y_label[train_num+1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression:  0.477\n",
      "Support Vector Machines:  0.469\n",
      "Nearest neighbours:  0.408\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "########\n",
    "clf_logreg = LogisticRegression()\n",
    "clf_logreg.fit(X_train, Y_train)\n",
    "print (\"Logistic regression: \", clf_logreg.score(X_test, Y_test) )\n",
    "########\n",
    "clf_svc = LinearSVC()\n",
    "clf_svc.fit(X_train, Y_train)\n",
    "print (\"Support Vector Machines: \", clf_svc.score(X_test, Y_test) )\n",
    "########\n",
    "clf_nei = neighbors.KNeighborsClassifier(num_class, weights='distance')\n",
    "clf_nei.fit(X_train, Y_train)\n",
    "print (\"Nearest neighbours: \", clf_nei.score(X_test, Y_test) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
